Inference Optimization: For TensorFlow Users
=============================================

* `How to accelerate a TensorFlow inference pipeline through ONNXRuntime <accelerate_tensorflow_inference_onnx.html>`_
* `How to accelerate a TensorFlow inference pipeline through OpenVINO <accelerate_tensorflow_inference_openvino.html>`_
* `How to conduct BFloat16 Mixed Precision inference in a TensorFlow Keras application <tensorflow_inference_bf16.html>`_
* `How to save and load optimized ONNXRuntime model in TensorFlow <tensorflow_save_and_load_onnx.html>`_
* `How to save and load optimized OpenVINO model in TensorFlow <tensorflow_save_and_load_openvino.html>`_
